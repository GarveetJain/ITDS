{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the last example empirically. Let's simulate a chain and empirically compute the expected times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Transition matrix from the example that we've solved\n",
    "P = np.array([\n",
    "    [0.5, 0.3, 0.2],\n",
    "    [0.1, 0.6, 0.3],\n",
    "    [0.0, 0.4, 0.6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.119123824764953)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Transition matrix from the example that we've solved\n",
    "# P = np.array([\n",
    "#     [0.5, 0.3, 0.2],\n",
    "#     [0.1, 0.6, 0.3],\n",
    "#     [0.0, 0.4, 0.6]\n",
    "# ])\n",
    "\n",
    "target_state = 2\n",
    "total_attempts = []\n",
    "for _ in range(10000):\n",
    "    prev_state = 0\n",
    "    attempts = 0\n",
    "    for _ in range(30):\n",
    "        cur_state = np.random.choice([0,1,2], p=P[prev_state,:])\n",
    "        attempts += 1\n",
    "        prev_state = cur_state\n",
    "        if cur_state == target_state:\n",
    "            total_attempts.append(attempts)\n",
    "            break\n",
    "    \n",
    "\n",
    "np.mean(total_attempts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Simulate a trajectory and return the time to hit target state.\n",
    "# def simulate_hitting_time(start_state, target_state=2, P=P, n=10000):\n",
    "\n",
    "#     # define the simulation length\n",
    "#     state = start_state\n",
    "#     t = 0\n",
    "#     # start the loop\n",
    "#     while t < n:\n",
    "#         if state == target_state:\n",
    "#             return t\n",
    "#         # we have 3 states: 0, 1, 2\n",
    "#         state = np.random.choice([0,1,2], p=P[state])\n",
    "#         t += 1\n",
    "#     return \n",
    "\n",
    "# # now repeat this simulation for a number of times nad compute the mean\n",
    "# def estimate_expected_time(start_state, trials=10000):\n",
    "#     times = []\n",
    "#     for _ in range(trials):\n",
    "#         ht = simulate_hitting_time(start_state)\n",
    "#         times.append(ht)\n",
    "#     return np.mean(times)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated E[T3, start at 1]: 4.1181 , analytical 4.1176\n",
      "Estimated E[T3, start at 2]: 3.5202 , analytical 3.5294\n"
     ]
    }
   ],
   "source": [
    "#  RUN SIMULATION \n",
    "\n",
    "trials = 20000\n",
    "\n",
    "est_h1 = estimate_expected_time(start_state=0, trials=trials)\n",
    "est_h2 = estimate_expected_time(start_state=1, trials=trials)\n",
    "\n",
    "print(f\"Estimated E[T3, start at 1]: {est_h1:.4f}\", ', analytical 4.1176')\n",
    "print(f\"Estimated E[T3, start at 2]: {est_h2:.4f}\", ', analytical 3.5294')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chains: some work with text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pride_and_prejudice.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#import numpy as np\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# first, read the text file\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# change encoding to utf-8-sig, otherwise it will add a Byte order mark (BOM, a unicode symbol) in the beginning of the file!\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mpride_and_prejudice.txt\u001b[39m\u001b[33m'\u001b[39m,mode=\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m,  encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8-sig\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      6\u001b[39m     book = f.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/intro_to_ds_starting_package/env/lib/python3.13/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, *args, **kwargs)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'pride_and_prejudice.txt'"
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "\n",
    "# first, read the text file\n",
    "# change encoding to utf-8-sig, otherwise it will add a Byte order mark (BOM, a unicode symbol) in the beginning of the file!\n",
    "with open('pride_and_prejudice.txt',mode='r',  encoding='utf-8-sig') as f:\n",
    "    book = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'book' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# let's remove some the text in the beginning and leave only the actual text of the book. \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m normal_words = book.split()[\u001b[32m105\u001b[39m:]\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# add dots\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(normal_words)):\n",
      "\u001b[31mNameError\u001b[39m: name 'book' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import itertools\n",
    "\n",
    "# let's remove some the text in the beginning and leave only the actual text of the book. \n",
    "normal_words = book.split()[105:]\n",
    "\n",
    "# add dots\n",
    "for i in range(len(normal_words)):\n",
    "    if '.' in normal_words[i] and len(normal_words[i]) > 1:\n",
    "        normal_words[i] = normal_words[i].replace(\".\", \"\")\n",
    "        normal_words.insert(i+1, '.')\n",
    "\n",
    "# and also remove some text in the end\n",
    "normal_words = normal_words[:len(normal_words)-2926]\n",
    "\n",
    "print(normal_words[len(normal_words)-10:len(normal_words)])\n",
    "\n",
    "\n",
    "# define the vector of states (unique words)\n",
    "# use this and not SET to preserve the order! \n",
    "states = list(OrderedDict.fromkeys(normal_words).keys())\n",
    "\n",
    "print(len(normal_words))\n",
    "print(len(states))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary where keys are the actual words and values are the integer labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# enumrate the states\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m labs = np.arange(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(states))\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# turn the sequence of words into a sequence of integers, and map them together into a dictionary\u001b[39;00m\n\u001b[32m      6\u001b[39m res = {states[i]: labs[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labs))}\n",
      "\u001b[31mNameError\u001b[39m: name 'states' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# enumrate the states\n",
    "labs = np.arange(0, len(states))\n",
    "\n",
    "# turn the sequence of words into a sequence of integers, and map them together into a dictionary\n",
    "res = {states[i]: labs[i] for i in range(len(labs))}\n",
    "\n",
    "print(res.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a method for mapping the words into integers and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_words_into_integers(normal_words):\n",
    "    mapped_words = []\n",
    "\n",
    "    for cur_word in normal_words:\n",
    "        cur_ind = list(res.keys()).index(cur_word)\n",
    "        mapped_words.append(list(res.values())[cur_ind])\n",
    "        \n",
    "    return mapped_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_integers_into_words(integers):\n",
    "    real_words = []\n",
    "\n",
    "    for cur_word in integers:\n",
    "        cur_ind = list(res.values()).index(cur_word)\n",
    "        real_words.append(list(res.keys())[cur_ind])\n",
    "        \n",
    "    return real_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and define a method to create transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(chain_seq):\n",
    "    # define number of states\n",
    "    n = 1+ max(chain_seq) \n",
    "    # create an empty nXn matrix, which we will fill in\n",
    "    M = np.zeros((n,n))\n",
    "    # zip is a useful method for working with matrices\n",
    "    # for each states, we add up to a matrix whenever we find this state in the sequence \n",
    "    for (i,j) in zip(chain_seq,chain_seq[1:]):\n",
    "        M[i][j] += 1\n",
    "\n",
    "    #now convert to probabilities:\n",
    "    M = M/M.sum(axis=1, keepdims=True)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test the function: first, make integers out of words (might take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function: first, make integers out of words (might take a while)\n",
    "\n",
    "words_mapped = map_words_into_integers(normal_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_words = transition_matrix(words_mapped)\n",
    "\n",
    "# check the sum across rows, should be one!\n",
    "p_words.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the probabilty of going form state \"the\" to \"her\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "237\n",
      "the\n",
      "her\n",
      "Probability of going from state THE to state HER is  0.0\n"
     ]
    }
   ],
   "source": [
    "ind1 = list(res.keys()).index('the')\n",
    "ind2 = list(res.keys()).index('her')\n",
    "\n",
    "print(ind1)\n",
    "print(ind2)\n",
    "\n",
    "print(states[ind1])\n",
    "print(states[ind2])\n",
    "\n",
    "# the probability of going from THE to HER we take directly from the matrix \n",
    "print('Probability of going from state THE to state HER is ', p_words[ind1, ind2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about \"His\" and \"wife\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of going from state HIS to state WIFE is  0.0\n"
     ]
    }
   ],
   "source": [
    "ind_his = list(res.keys()).index('his')\n",
    "ind_wife = list(res.keys()).index('wife')\n",
    "\n",
    "p_words[ind_his, ind_wife]\n",
    "\n",
    "print('Probability of going from state HIS to state WIFE is ', p_words[ind1, ind2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also estimate the expected number of steps required to go from \"the\" to \"her\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1 = list(res.keys()).index('the')\n",
    "ind2 = list(res.keys()).index('her')\n",
    "\n",
    "## first, find all indices of \"her\" and \"the\" in the sequence\n",
    "starts = [i for i, x in enumerate(words_mapped) if x == ind1]\n",
    "ends   = [i for i, x in enumerate(words_mapped) if x ==ind2]\n",
    "\n",
    "## now take the length of ALL subsets WITH these indicies\n",
    "#all_subsets_required_states = [len(words_mapped[start:end+1]) for start,end in zip(starts, ends)]\n",
    "########3 this does not keep the order! Try this:\n",
    "\n",
    "# define a function that takes a vector of integers, start index and end index, and finds all\n",
    "# subsequence between these indices \n",
    "def get_length_all_sequences(seq, ind1, ind2):\n",
    "    # set a count of steps\n",
    "    count = 0\n",
    "    # set a flag\n",
    "    fl = 0\n",
    "    # keep the length of all sequences between \"The\" and \"Her\"\n",
    "    sequence_length = []\n",
    "    for i in seq:\n",
    "        if i == ind1:\n",
    "            fl = 1\n",
    "        elif i == ind2:\n",
    "            fl = 0\n",
    "            sequence_length.append(count)\n",
    "            count = 0\n",
    "        # if flag is on, i count words\n",
    "        if fl: \n",
    "            count+= 1\n",
    "    return sequence_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4529.444444444444"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind1 = list(res.keys()).index('his')\n",
    "ind2 = list(res.keys()).index('wife')\n",
    "\n",
    "# and compute the mean\n",
    "sequence_length = get_length_all_sequences(words_mapped,ind1, ind2)\n",
    "np.mean(sequence_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some fun with text: Generate samplings of your own text using the estimated probability matrix! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# function that generates text\n",
    "def generate_text(states, p_words, init_state, N_words):\n",
    "\n",
    "        # generate some text with N words\n",
    "\n",
    "        # for the current word, generate the new word k times and choose the most common one\n",
    "        k = 100\n",
    "        N = N_words\n",
    "\n",
    "        n_states = len(states)\n",
    "        # p_words is the matrix\n",
    "\n",
    "        # initial state:\n",
    "        i1 = init_state\n",
    "        all_words = [i1]\n",
    "        for i in range(1, N):\n",
    "            # all words generated k times for the current state\n",
    "            cur_states_word = []\n",
    "            # given the current state, choose the column of the matrix accordingly \n",
    "            p_column = p_words[all_words[i-1]]\n",
    "            # generate k words according to the matrix\n",
    "            for j in range(k):\n",
    "                cur_states_word.append(np.random.choice(np.arange(0, n_states), p = p_column))\n",
    "                \n",
    "            # now choose the most common word\n",
    "            most_common_word = list(Counter(cur_states_word).most_common(1)[0])[0]\n",
    "            all_words.append(most_common_word)\n",
    "            \n",
    "        return all_words\n",
    "\n",
    "def generate_and_write(p_words, init_state, filename, N_words):\n",
    "\n",
    "\n",
    "    text_integers = generate_text(states, p_words, init_state, N_words)\n",
    "    my_text = map_integers_into_words(text_integers)\n",
    "\n",
    "    whole_text = ' '.join(my_text)\n",
    "\n",
    "    with open(filename, \"w\") as text_file:\n",
    "        text_file.write(whole_text)\n",
    "        \n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She was very great deal of her . I am sure you must be in'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_my_book = p_words\n",
    "\n",
    "p_my_book[np.isnan(p_my_book)] = 0\n",
    "\n",
    "\n",
    "in_state = ind2 = list(res.keys()).index('She')\n",
    "\n",
    "text = generate_and_write(p_my_book, in_state, 'some-text-new-try.txt', 15)\n",
    "text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chain examples: Stationary distribuiton. Recall: pi*M = pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.5, 0.5],\n",
       "       [0. , 0.3, 0.7],\n",
       "       [1. , 0. , 0. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# define some matrix of probabilities\n",
    "transition_matrix = np.array([[0,0.5,0.5],\n",
    "                              [0,0.3,0.7],\n",
    "                              [1,0,0]])\n",
    "\n",
    "# do the rows sum to 1?\n",
    "print(transition_matrix.sum(axis=1))\n",
    "\n",
    "transition_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " No built-in method to find stationary distribution. One of the algorithms:\n",
    " Find the eigenvector with an eigenvalue that is are close to one. To compute the stationary distribution, every element in the selected eigenvector is divided by the sum of the eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the matrix\n",
    "transition_matrix_t = transition_matrix.T\n",
    "# use linear algebra module of numpy to compute the eigenvalues\n",
    "eigenvals, eigenvects = np.linalg.eig(transition_matrix_t)\n",
    "\n",
    "# Find the indexes of the eigenvalues that are close to one.\n",
    "close_to_1_idx = np.isclose(eigenvals,1) # isclose checks element-wise if each element is close to 1 within the specific tolerance\n",
    "# Use them to select the target eigen vectors\n",
    "target_eigenvect = eigenvects[:,close_to_1_idx]\n",
    "#Flatten\n",
    "target_eigenvect = target_eigenvect[:,0]\n",
    "# Turn the eigenvector elements into probabilities\n",
    "# that would be the stationary distribution\n",
    "st_d = target_eigenvect / sum(target_eigenvect) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36842105 0.26315789 0.36842105]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the real part of the probability\n",
    "print(st_d.real)\n",
    "\n",
    "# our stationary distribution pi\n",
    "real_st_distr = st_d.real\n",
    "\n",
    "# check if they sum to 1\n",
    "st_d.real.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the fixed point equation: pi*M = pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36842105, 0.26315789, 0.36842105])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_st_distr.dot(transition_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
